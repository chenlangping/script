from openai import OpenAI
from pydub import AudioSegment
import math
import os
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import threading
import time

# ç¹ä½“è½¬ç®€ä½“æ˜ å°„ï¼ˆå¸¸ç”¨å­—ï¼‰
def traditional_to_simplified(text):
    """
    å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
    ä½¿ç”¨ opencc-python-reimplemented åº“ï¼ˆéœ€è¦å®‰è£…: pip install opencc-python-reimplementedï¼‰
    å¦‚æœæ²¡æœ‰å®‰è£…è¯¥åº“ï¼Œä¼šä½¿ç”¨å†…ç½®çš„åŸºç¡€è½¬æ¢
    """
    try:
        from opencc import OpenCC
        cc = OpenCC('t2s')  # t2s = Traditional to Simplified
        return cc.convert(text)
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£… openccï¼Œæç¤ºç”¨æˆ·å®‰è£…
        print("âš ï¸  å»ºè®®å®‰è£… opencc-python-reimplemented ä»¥è·å¾—æ›´å¥½çš„ç¹ç®€è½¬æ¢æ•ˆæœ")
        print("   å®‰è£…å‘½ä»¤: pip install opencc-python-reimplemented")
        # è¿”å›åŸæ–‡æœ¬
        return text

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# çº¿ç¨‹é”ï¼Œç”¨äºä¿æŠ¤å…±äº«èµ„æº
lock = threading.Lock()

def split_audio(file_path, chunk_length_ms=60000):
    """
    æŠŠéŸ³é¢‘åˆ‡åˆ†æˆå°æ®µï¼Œé»˜è®¤æ¯æ®µ 60 ç§’
    """
    print("ğŸµ æ­£åœ¨åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
    audio = AudioSegment.from_file(file_path)
    total_chunks = math.ceil(len(audio) / chunk_length_ms)
    chunks = []

    print(f"ğŸ“Š éŸ³é¢‘æ€»æ—¶é•¿: {len(audio) / 1000:.1f} ç§’")
    print(f"âœ‚ï¸  å°†åˆ‡åˆ†ä¸º {total_chunks} æ®µ (æ¯æ®µ {chunk_length_ms/1000:.0f} ç§’)")

    # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºåˆ‡åˆ†è¿›åº¦
    with tqdm(total=total_chunks, desc="åˆ‡åˆ†éŸ³é¢‘", unit="æ®µ", ncols=80) as pbar:
        for i in range(0, len(audio), chunk_length_ms):
            chunk = audio[i:i+chunk_length_ms]
            chunk_name = f"chunk_{i//chunk_length_ms:03d}.mp3"
            chunk.export(chunk_name, format="mp3")
            chunks.append(chunk_name)
            pbar.update(1)

    print(f"âœ… éŸ³é¢‘åˆ‡åˆ†å®Œæˆï¼Œç”Ÿæˆ {len(chunks)} ä¸ªç‰‡æ®µæ–‡ä»¶")
    return chunks

def transcribe_single_chunk(chunk_info):
    """
    è½¬å†™å•ä¸ªéŸ³é¢‘ç‰‡æ®µ
    chunk_info: (index, filename, start_time_seconds) å…ƒç»„
    """
    idx, chunk_file, start_time = chunk_info
    
    try:
        with open(chunk_file, "rb") as f:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=f,
                language="zh",  # æŒ‡å®šä¸­æ–‡
                response_format="text"  # ç›´æ¥è·å–æ–‡æœ¬
            )
        
        # è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡
        simplified_text = traditional_to_simplified(transcript)
        
        return idx, simplified_text, start_time, None
    except Exception as e:
        return idx, None, start_time, str(e)

def transcribe_audio_threaded(chunks, max_workers=4, chunk_length_seconds=60):
    """
    ä½¿ç”¨å¤šçº¿ç¨‹è½¬å†™éŸ³é¢‘ç‰‡æ®µ
    """
    total_chunks = len(chunks)
    results = {}  # æ”¹ä¸ºå­—å…¸ï¼Œç”¨ç´¢å¼•ä½œä¸ºé”®
    errors = []
    
    print(f"ğŸš€ å¼€å§‹å¤šçº¿ç¨‹è½¬å†™ï¼Œä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹")
    print(f"ğŸ“ å…±éœ€å¤„ç† {total_chunks} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
    
    # å‡†å¤‡ä»»åŠ¡æ•°æ®ï¼š(ç´¢å¼•, æ–‡ä»¶å, å¼€å§‹æ—¶é—´)
    chunk_tasks = [
        (i, chunk, i * chunk_length_seconds) 
        for i, chunk in enumerate(chunks)
    ]
    
    # ä½¿ç”¨çº¿ç¨‹æ± å’Œè¿›åº¦æ¡
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_chunk = {
            executor.submit(transcribe_single_chunk, task): task 
            for task in chunk_tasks
        }
        
        # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºè½¬å†™è¿›åº¦
        with tqdm(total=total_chunks, desc="è½¬å†™è¿›åº¦", unit="æ®µ", ncols=80) as pbar:
            for future in as_completed(future_to_chunk):
                chunk_info = future_to_chunk[future]
                try:
                    idx, text, start_time, error = future.result()
                    if error:
                        errors.append(f"ç‰‡æ®µ {idx}: {error}")
                        pbar.write(f"âŒ ç‰‡æ®µ {idx} è½¬å†™å¤±è´¥: {error}")
                    else:
                        # æ ¼å¼åŒ–æ—¶é—´æˆ³
                        minutes, seconds = divmod(start_time, 60)
                        hours, minutes = divmod(minutes, 60)
                        timestamp = f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}"
                        
                        # å­˜å‚¨ä¸ºå­—å…¸ï¼Œç¡®ä¿æŒ‰ç´¢å¼•æ’åº
                        results[idx] = (timestamp, text)
                        
                        # æ˜¾ç¤ºéƒ¨åˆ†è½¬å†™ç»“æœé¢„è§ˆï¼ˆé™åˆ¶å­—ç¬¦æ•°é¿å…è¾“å‡ºè¿‡é•¿ï¼‰
                        preview = text[:40] + "..." if len(text) > 40 else text
                        pbar.write(f"âœ… [{timestamp}] ç‰‡æ®µ {idx:3d}: {preview}")
                    
                except Exception as e:
                    idx = chunk_info[0]
                    errors.append(f"ç‰‡æ®µ {idx}: {str(e)}")
                    pbar.write(f"ğŸ’¥ ç‰‡æ®µ {idx} å¤„ç†å¼‚å¸¸: {str(e)}")
                
                pbar.update(1)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„ç‰‡æ®µ
    if errors:
        print(f"\nâš ï¸  æœ‰ {len(errors)} ä¸ªç‰‡æ®µè½¬å†™å¤±è´¥:")
        for error in errors:
            print(f"   {error}")
    
    # æŒ‰ç´¢å¼•é¡ºåºæ’åºå¹¶è¿”å›ç»“æœ
    sorted_results = []
    for i in range(total_chunks):
        if i in results:
            sorted_results.append(results[i])
    
    print(f"\nğŸ“Š è½¬å†™ç»Ÿè®¡:")
    print(f"   æˆåŠŸ: {len(sorted_results)}/{total_chunks} ä¸ªç‰‡æ®µ")
    print(f"   å¤±è´¥: {len(errors)} ä¸ªç‰‡æ®µ")
    
    return sorted_results

def merge_text(results, output_file="transcript.txt"):
    """
    åˆå¹¶æ‰€æœ‰ç‰‡æ®µæ–‡å­—å¹¶ä¿å­˜ï¼ŒåŒ…å«æ—¶é—´æˆ³
    results: åŒ…å« (timestamp, text) å…ƒç»„çš„åˆ—è¡¨
    """
    if not results:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„è½¬å†™ç»“æœ")
        return None
        
    print(f"ğŸ“ æ­£åœ¨åˆå¹¶ {len(results)} æ®µæ–‡å­—...")
    
    # æ„å»ºåŒ…å«æ—¶é—´æˆ³çš„å®Œæ•´æ–‡æœ¬
    formatted_segments = []
    for timestamp, text in results:
        formatted_segments.append(f"[{timestamp}] {text}")
    
    full_text = "\n\n".join(formatted_segments)
    
    # åŒæ—¶åˆ›å»ºä¸€ä¸ªä¸å¸¦æ—¶é—´æˆ³çš„çº¯æ–‡æœ¬ç‰ˆæœ¬
    pure_text = "\n\n".join([text for _, text in results])
    
    # ä¿å­˜å¸¦æ—¶é—´æˆ³ç‰ˆæœ¬ï¼ˆä½¿ç”¨ UTF-8 ç¼–ç ç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤ºï¼‰
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(full_text)
    
    # ä¿å­˜çº¯æ–‡æœ¬ç‰ˆæœ¬
    pure_text_file = output_file.replace('.txt', '_pure.txt')
    with open(pure_text_file, "w", encoding="utf-8") as f:
        f.write(pure_text)
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    word_count = len(pure_text.split())
    char_count = len(pure_text)
    
    print(f"âœ… è½¬å†™å®Œæˆ!")
    print(f"ğŸ“„ æ–‡ä»¶ä¿å­˜:")
    print(f"   å¸¦æ—¶é—´æˆ³: {output_file}")
    print(f"   çº¯æ–‡æœ¬ç‰ˆ: {pure_text_file}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   å­—ç¬¦æ•°: {char_count:,}")
    print(f"   è¯è¯­æ•°: {word_count:,}")
    
    return output_file

def cleanup_chunks(chunks):
    """
    æ¸…ç†ä¸´æ—¶éŸ³é¢‘ç‰‡æ®µæ–‡ä»¶
    """
    print("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    cleaned = 0
    for chunk in chunks:
        try:
            if os.path.exists(chunk):
                os.remove(chunk)
                cleaned += 1
        except Exception as e:
            print(f"âš ï¸  æ— æ³•åˆ é™¤ {chunk}: {e}")
    
    print(f"âœ… å·²æ¸…ç† {cleaned} ä¸ªä¸´æ—¶æ–‡ä»¶")

def main():
    # é…ç½®å‚æ•°
    input_file = "/Users/SomeUser/Downloads/output-2.m4a"  # ä¿®æ”¹ä¸ºä½ çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    chunk_length_seconds = 60      # æ¯æ®µéŸ³é¢‘é•¿åº¦ï¼ˆç§’ï¼‰
    max_workers = 16                # æœ€å¤§çº¿ç¨‹æ•°
    output_file = "transcript.txt" # è¾“å‡ºæ–‡ä»¶å
    cleanup_temp_files = True      # æ˜¯å¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    
    print("ğŸ™ï¸  è¯­éŸ³è½¬æ–‡å­—å·¥å…· (å¤šçº¿ç¨‹ç‰ˆ - ç®€ä½“ä¸­æ–‡)")
    print("=" * 50)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(input_file):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°éŸ³é¢‘æ–‡ä»¶ '{input_file}'")
        print("è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ input_file å˜é‡ä¸ºæ­£ç¡®çš„æ–‡ä»¶è·¯å¾„")
        return
    
    # æ£€æŸ¥ API Key
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export OPENAI_API_KEY='your-api-key'")
        return
    
    try:
        start_time = time.time()
        
        # æ­¥éª¤1: åˆ‡åˆ†éŸ³é¢‘
        chunks = split_audio(input_file, chunk_length_ms=chunk_length_seconds*1000)
        
        # æ­¥éª¤2: å¤šçº¿ç¨‹è½¬å†™
        results = transcribe_audio_threaded(chunks, max_workers=max_workers, 
                                          chunk_length_seconds=chunk_length_seconds)
        
        # æ­¥éª¤3: åˆå¹¶ç»“æœ
        final_output = merge_text(results, output_file)
        
        # æ­¥éª¤4: æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if cleanup_temp_files:
            cleanup_chunks(chunks)
        
        # æ˜¾ç¤ºæ€»è€—æ—¶
        total_time = time.time() - start_time
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {total_time:.1f} ç§’")
        
        if final_output:
            print(f"ğŸ‰ å…¨éƒ¨å®Œæˆ! ç»“æœä¿å­˜åœ¨: {final_output}")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        if 'chunks' in locals():
            cleanup_chunks(chunks)
    except Exception as e:
        print(f"\nğŸ’¥ å‘ç”Ÿé”™è¯¯: {str(e)}")
        if 'chunks' in locals():
            cleanup_chunks(chunks)

if __name__ == "__main__":
    main()